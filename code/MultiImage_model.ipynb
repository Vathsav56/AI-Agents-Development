{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YDLC6H8kXj0SDjhTaC9GyNfY212v9Vxz",
      "authorship_tag": "ABX9TyP8MQgRFOOPADLNxqNpFkYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vathsav56/AI-Agents-Development/blob/main/code/MultiImage_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNNR5cYJ2vr5",
        "outputId": "70db129e-5d77-44cd-ff5a-39966a8c9ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/car-classifier.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "s1EW5-qt4tZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/drive/MyDrive/cardataset/Test/audi/21.jpg' , target_size=(64,64))"
      ],
      "metadata": {
        "id": "G90Q2sS14tcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "ig = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "uP5vogcV4tit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VrGELaES4tlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = img_to_array(img)\n",
        "img_array = np.expand_dims(image_array, axis=0)\n",
        "newimg = ig.flow(img_array)"
      ],
      "metadata": {
        "id": "3Q5c3SSc4yyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_names = ['audi', 'lamborghini', 'mercedes']\n",
        "\n",
        "pred = model.predict(newimg)\n",
        "\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPEGZDW04yq8",
        "outputId": "7798e174-6574-4fa5-b90b-0c15ae13cd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.4983411e-05 9.7984296e-01 2.0092076e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = list(pred.flatten())\n",
        "print(class_names[a.index(max(a))])"
      ],
      "metadata": {
        "id": "M_Choc5n4yoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3755436e-5f1e-43a1-c4bf-000caf9c6062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamborghini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me para about ai models in general\n",
        "\n",
        "Artificial intelligence (AI) models are computational systems designed to perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. These models are built using various algorithms and techniques, often drawing inspiration from how the human brain processes information. Machine learning, a key subset of AI, focuses on developing algorithms that allow computers to learn from data without being explicitly programmed. Deep learning, a further specialization of machine learning, utilizes artificial neural networks with multiple layers to model complex patterns in data. AI models can be trained on massive datasets to identify trends, make predictions, classify information, and even generate new content. They are widely applied across diverse fields, including image and speech recognition, natural language processing, healthcare, finance, and autonomous systems. The process of developing and deploying an AI model typically involves collecting and preparing data, choosing an appropriate model architecture, training the model, and then evaluating and refining its performance."
      ],
      "metadata": {
        "id": "AW6L0z_MAplM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}